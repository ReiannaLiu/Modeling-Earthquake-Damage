{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report, f1_score, confusion_matrix, roc_auc_score, precision_score, recall_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "X_train = pd.read_csv('../Resources/Datasets/X_train.csv', index_col=0)\n",
    "y_train = pd.read_csv('../Resources/Datasets/y_train.csv', index_col=0)\n",
    "X_test = pd.read_csv('../Resources/Datasets/X_test.csv', index_col=0)\n",
    "y_test = pd.read_csv('../Resources/Datasets/y_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [201445, 208480]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mnn, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Fit the grid search to the data\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Print the best parameters found\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Users\\reian\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\reian\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:806\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_refit_for_multimetric(scorers)\n\u001b[0;32m    804\u001b[0m     refit_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit\n\u001b[1;32m--> 806\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    807\u001b[0m fit_params \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[0;32m    809\u001b[0m cv_orig \u001b[38;5;241m=\u001b[39m check_cv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv, y, classifier\u001b[38;5;241m=\u001b[39mis_classifier(estimator))\n",
      "File \u001b[1;32mc:\\Users\\reian\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:453\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    452\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 453\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\reian\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [201445, 208480]"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid based on the results of random search\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "nn = MLPClassifier(random_state=42, early_stopping=True, max_iter=400, n_iter_no_change=20, verbose=True)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=nn, param_grid=param_grid, scoring='f1_weighted', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Print the best parameters found\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 5.03877758\n",
      "Validation score: 0.349338\n",
      "Iteration 2, loss = 2.08335459\n",
      "Validation score: 0.558663\n",
      "Iteration 3, loss = 1.63697481\n",
      "Validation score: 0.429106\n",
      "Iteration 4, loss = 1.24433394\n",
      "Validation score: 0.575163\n",
      "Iteration 5, loss = 1.05132229\n",
      "Validation score: 0.535495\n",
      "Iteration 6, loss = 1.03672321\n",
      "Validation score: 0.471556\n",
      "Iteration 7, loss = 0.92755423\n",
      "Validation score: 0.574156\n",
      "Iteration 8, loss = 0.89267799\n",
      "Validation score: 0.558711\n",
      "Iteration 9, loss = 0.89194056\n",
      "Validation score: 0.567920\n",
      "Iteration 10, loss = 0.86828826\n",
      "Validation score: 0.564323\n",
      "Iteration 11, loss = 0.85231873\n",
      "Validation score: 0.526046\n",
      "Iteration 12, loss = 0.83132464\n",
      "Validation score: 0.572189\n",
      "Iteration 13, loss = 0.82936215\n",
      "Validation score: 0.572333\n",
      "Iteration 14, loss = 0.82445594\n",
      "Validation score: 0.572093\n",
      "Iteration 15, loss = 0.81777744\n",
      "Validation score: 0.551756\n",
      "Iteration 16, loss = 0.81757443\n",
      "Validation score: 0.570079\n",
      "Iteration 17, loss = 0.81303046\n",
      "Validation score: 0.561733\n",
      "Iteration 18, loss = 0.81044547\n",
      "Validation score: 0.572765\n",
      "Iteration 19, loss = 0.80811664\n",
      "Validation score: 0.579384\n",
      "Iteration 20, loss = 0.80264606\n",
      "Validation score: 0.585524\n",
      "Iteration 21, loss = 0.80401099\n",
      "Validation score: 0.575643\n",
      "Iteration 22, loss = 0.80297371\n",
      "Validation score: 0.580295\n",
      "Iteration 23, loss = 0.79975692\n",
      "Validation score: 0.595357\n",
      "Iteration 24, loss = 0.79588376\n",
      "Validation score: 0.587490\n",
      "Iteration 25, loss = 0.79519024\n",
      "Validation score: 0.588785\n",
      "Iteration 26, loss = 0.79415194\n",
      "Validation score: 0.579096\n",
      "Iteration 27, loss = 0.79245933\n",
      "Validation score: 0.583413\n",
      "Iteration 28, loss = 0.79220923\n",
      "Validation score: 0.600106\n",
      "Iteration 29, loss = 0.78908215\n",
      "Validation score: 0.604135\n",
      "Iteration 30, loss = 0.78627632\n",
      "Validation score: 0.595405\n",
      "Iteration 31, loss = 0.78695540\n",
      "Validation score: 0.606005\n",
      "Iteration 32, loss = 0.78656955\n",
      "Validation score: 0.592479\n",
      "Iteration 33, loss = 0.78559698\n",
      "Validation score: 0.607109\n",
      "Iteration 34, loss = 0.78545833\n",
      "Validation score: 0.595165\n",
      "Iteration 35, loss = 0.78262468\n",
      "Validation score: 0.606629\n",
      "Iteration 36, loss = 0.78334502\n",
      "Validation score: 0.585188\n",
      "Iteration 37, loss = 0.78130073\n",
      "Validation score: 0.595741\n",
      "Iteration 38, loss = 0.78077484\n",
      "Validation score: 0.599818\n",
      "Iteration 39, loss = 0.77765636\n",
      "Validation score: 0.611186\n",
      "Iteration 40, loss = 0.77937161\n",
      "Validation score: 0.592239\n",
      "Iteration 41, loss = 0.78113892\n",
      "Validation score: 0.599482\n",
      "Iteration 42, loss = 0.77753572\n",
      "Validation score: 0.608596\n",
      "Iteration 43, loss = 0.77830138\n",
      "Validation score: 0.607540\n",
      "Iteration 44, loss = 0.77756590\n",
      "Validation score: 0.603319\n",
      "Iteration 45, loss = 0.77693443\n",
      "Validation score: 0.608644\n",
      "Iteration 46, loss = 0.77627850\n",
      "Validation score: 0.613680\n",
      "Iteration 47, loss = 0.77478827\n",
      "Validation score: 0.612241\n",
      "Iteration 48, loss = 0.77502405\n",
      "Validation score: 0.607252\n",
      "Iteration 49, loss = 0.77465299\n",
      "Validation score: 0.608979\n",
      "Iteration 50, loss = 0.77375195\n",
      "Validation score: 0.607109\n",
      "Iteration 51, loss = 0.77426083\n",
      "Validation score: 0.614208\n",
      "Iteration 52, loss = 0.77363224\n",
      "Validation score: 0.609267\n",
      "Iteration 53, loss = 0.77214950\n",
      "Validation score: 0.605526\n",
      "Iteration 54, loss = 0.77165763\n",
      "Validation score: 0.611857\n",
      "Iteration 55, loss = 0.77267962\n",
      "Validation score: 0.606389\n",
      "Iteration 56, loss = 0.77098844\n",
      "Validation score: 0.602072\n",
      "Iteration 57, loss = 0.77105761\n",
      "Validation score: 0.612865\n",
      "Iteration 58, loss = 0.77168561\n",
      "Validation score: 0.613632\n",
      "Iteration 59, loss = 0.76858126\n",
      "Validation score: 0.571566\n",
      "Iteration 60, loss = 0.77006550\n",
      "Validation score: 0.608452\n",
      "Iteration 61, loss = 0.76778229\n",
      "Validation score: 0.610178\n",
      "Iteration 62, loss = 0.76866746\n",
      "Validation score: 0.608931\n",
      "Iteration 63, loss = 0.76688494\n",
      "Validation score: 0.611186\n",
      "Iteration 64, loss = 0.76856130\n",
      "Validation score: 0.606917\n",
      "Iteration 65, loss = 0.76582162\n",
      "Validation score: 0.611617\n",
      "Iteration 66, loss = 0.76719120\n",
      "Validation score: 0.599098\n",
      "Iteration 67, loss = 0.76636172\n",
      "Validation score: 0.610418\n",
      "Iteration 68, loss = 0.76622239\n",
      "Validation score: 0.613872\n",
      "Iteration 69, loss = 0.76489557\n",
      "Validation score: 0.618908\n",
      "Iteration 70, loss = 0.76422770\n",
      "Validation score: 0.608452\n",
      "Iteration 71, loss = 0.76410938\n",
      "Validation score: 0.615455\n",
      "Iteration 72, loss = 0.76372313\n",
      "Validation score: 0.621259\n",
      "Iteration 73, loss = 0.76488327\n",
      "Validation score: 0.620971\n",
      "Iteration 74, loss = 0.76223237\n",
      "Validation score: 0.617661\n",
      "Iteration 75, loss = 0.76298836\n",
      "Validation score: 0.625000\n",
      "Iteration 76, loss = 0.76152676\n",
      "Validation score: 0.621067\n",
      "Iteration 77, loss = 0.76004487\n",
      "Validation score: 0.614831\n",
      "Iteration 78, loss = 0.75973695\n",
      "Validation score: 0.611521\n",
      "Iteration 79, loss = 0.76114266\n",
      "Validation score: 0.626775\n",
      "Iteration 80, loss = 0.76016292\n",
      "Validation score: 0.612001\n",
      "Iteration 81, loss = 0.75852162\n",
      "Validation score: 0.623033\n",
      "Iteration 82, loss = 0.75843137\n",
      "Validation score: 0.618237\n",
      "Iteration 83, loss = 0.75508452\n",
      "Validation score: 0.614831\n",
      "Iteration 84, loss = 0.75664539\n",
      "Validation score: 0.632099\n",
      "Iteration 85, loss = 0.75524501\n",
      "Validation score: 0.623753\n",
      "Iteration 86, loss = 0.75309687\n",
      "Validation score: 0.617325\n",
      "Iteration 87, loss = 0.75202204\n",
      "Validation score: 0.610274\n",
      "Iteration 88, loss = 0.75484872\n",
      "Validation score: 0.632866\n",
      "Iteration 89, loss = 0.75299892\n",
      "Validation score: 0.630996\n",
      "Iteration 90, loss = 0.74979523\n",
      "Validation score: 0.625672\n",
      "Iteration 91, loss = 0.74908491\n",
      "Validation score: 0.624520\n",
      "Iteration 92, loss = 0.75060481\n",
      "Validation score: 0.618860\n",
      "Iteration 93, loss = 0.74955647\n",
      "Validation score: 0.621259\n",
      "Iteration 94, loss = 0.74906029\n",
      "Validation score: 0.627254\n",
      "Iteration 95, loss = 0.74695834\n",
      "Validation score: 0.607684\n",
      "Iteration 96, loss = 0.75016452\n",
      "Validation score: 0.631380\n",
      "Iteration 97, loss = 0.74832936\n",
      "Validation score: 0.630996\n",
      "Iteration 98, loss = 0.74638629\n",
      "Validation score: 0.621642\n",
      "Iteration 99, loss = 0.74571498\n",
      "Validation score: 0.627111\n",
      "Iteration 100, loss = 0.74438411\n",
      "Validation score: 0.633346\n",
      "Iteration 101, loss = 0.74455327\n",
      "Validation score: 0.626103\n",
      "Iteration 102, loss = 0.74369175\n",
      "Validation score: 0.620875\n",
      "Iteration 103, loss = 0.74292728\n",
      "Validation score: 0.625000\n",
      "Iteration 104, loss = 0.74268210\n",
      "Validation score: 0.633730\n",
      "Iteration 105, loss = 0.74236145\n",
      "Validation score: 0.638526\n",
      "Iteration 106, loss = 0.74101205\n",
      "Validation score: 0.634881\n",
      "Iteration 107, loss = 0.73994685\n",
      "Validation score: 0.636656\n",
      "Iteration 108, loss = 0.74118855\n",
      "Validation score: 0.642652\n",
      "Iteration 109, loss = 0.74039456\n",
      "Validation score: 0.633106\n",
      "Iteration 110, loss = 0.73826721\n",
      "Validation score: 0.630996\n",
      "Iteration 111, loss = 0.73851458\n",
      "Validation score: 0.625959\n",
      "Iteration 112, loss = 0.74277709\n",
      "Validation score: 0.621259\n",
      "Iteration 113, loss = 0.73868589\n",
      "Validation score: 0.623657\n",
      "Iteration 114, loss = 0.73645861\n",
      "Validation score: 0.651333\n",
      "Iteration 115, loss = 0.73714163\n",
      "Validation score: 0.633058\n",
      "Iteration 116, loss = 0.73620190\n",
      "Validation score: 0.638718\n",
      "Iteration 117, loss = 0.73656416\n",
      "Validation score: 0.633058\n",
      "Iteration 118, loss = 0.73984919\n",
      "Validation score: 0.634785\n",
      "Iteration 119, loss = 0.73451233\n",
      "Validation score: 0.639150\n",
      "Iteration 120, loss = 0.73516579\n",
      "Validation score: 0.632243\n",
      "Iteration 121, loss = 0.73411449\n",
      "Validation score: 0.633682\n",
      "Iteration 122, loss = 0.73485801\n",
      "Validation score: 0.643659\n",
      "Iteration 123, loss = 0.73404694\n",
      "Validation score: 0.636944\n",
      "Iteration 124, loss = 0.73374063\n",
      "Validation score: 0.627878\n",
      "Iteration 125, loss = 0.73314053\n",
      "Validation score: 0.617853\n",
      "Iteration 126, loss = 0.73503482\n",
      "Validation score: 0.632818\n",
      "Iteration 127, loss = 0.73268225\n",
      "Validation score: 0.647496\n",
      "Iteration 128, loss = 0.73323302\n",
      "Validation score: 0.635792\n",
      "Iteration 129, loss = 0.73272270\n",
      "Validation score: 0.649319\n",
      "Iteration 130, loss = 0.73207768\n",
      "Validation score: 0.642891\n",
      "Iteration 131, loss = 0.73041972\n",
      "Validation score: 0.642364\n",
      "Iteration 132, loss = 0.73085847\n",
      "Validation score: 0.649799\n",
      "Iteration 133, loss = 0.73380516\n",
      "Validation score: 0.643419\n",
      "Iteration 134, loss = 0.73200576\n",
      "Validation score: 0.638047\n",
      "Iteration 135, loss = 0.73384734\n",
      "Validation score: 0.640973\n",
      "Validation score did not improve more than tol=0.000100 for 20 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "# train the model with the best parameters\n",
    "nn = grid_search.best_estimator_\n",
    "nn.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# predict the test set\n",
    "y_pred = nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>weighted_f1_score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     accuracy  precision  recall  weighted_f1_score  AUC   AP\n",
       "Model                                                                        \n",
       "Decision Tree             0.0        0.0     0.0                0.0  0.0  0.0\n",
       "Random Forest             0.0        0.0     0.0                0.0  0.0  0.0\n",
       "XGB                       0.0        0.0     0.0                0.0  0.0  0.0\n",
       "SVM                       0.0        0.0     0.0                0.0  0.0  0.0\n",
       "KNN                       0.0        0.0     0.0                0.0  0.0  0.0\n",
       "Logistic Regression       0.0        0.0     0.0                0.0  0.0  0.0\n",
       "Naive Bayes               0.0        0.0     0.0                0.0  0.0  0.0\n",
       "Neural Network            0.0        0.0     0.0                0.0  0.0  0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.read_csv('../Resources/Datasets/results.csv', index_col=0)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.38      0.47      5025\n",
      "           2       0.66      0.84      0.74     29652\n",
      "           3       0.66      0.43      0.52     17444\n",
      "\n",
      "    accuracy                           0.66     52121\n",
      "   macro avg       0.65      0.55      0.58     52121\n",
      "weighted avg       0.66      0.66      0.64     52121\n",
      "\n",
      "[[ 1887  3034   104]\n",
      " [ 1055 24828  3769]\n",
      " [   66  9886  7492]]\n",
      "Accuracy Score: 0.6562997640106675\n",
      "F1 Score (Weighted): 0.6385024992101994\n",
      "Precision Score (Weighted): 0.6552966084251843\n",
      "Recall Score (Weighted): 0.6562997640106675\n",
      "ROC AUC Score: 0.7355116343837474\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score (Weighted):\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Precision Score (Weighted):\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall Score (Weighted):\", recall_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "y_pred_proba = grid_search.best_estimator_.predict_proba(X_test)\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the results dataframe\n",
    "result_df.loc['Neural Network'] = [accuracy_score(y_test, y_pred), \n",
    "                                   precision_score(y_test, y_pred, average='weighted'), \n",
    "                                   recall_score(y_test, y_pred, average='weighted'), \n",
    "                                   f1_score(y_test, y_pred, average='weighted'), \n",
    "                                   roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='weighted'), \n",
    "                                   average_precision_score(y_test, y_pred_proba, average='weighted')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>weighted_f1_score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>0.6563</td>\n",
       "      <td>0.655297</td>\n",
       "      <td>0.6563</td>\n",
       "      <td>0.638502</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.669619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     accuracy  precision  recall  weighted_f1_score       AUC  \\\n",
       "Model                                                                           \n",
       "Decision Tree          0.0000   0.000000  0.0000           0.000000  0.000000   \n",
       "Random Forest          0.0000   0.000000  0.0000           0.000000  0.000000   \n",
       "XGB                    0.0000   0.000000  0.0000           0.000000  0.000000   \n",
       "SVM                    0.0000   0.000000  0.0000           0.000000  0.000000   \n",
       "KNN                    0.0000   0.000000  0.0000           0.000000  0.000000   \n",
       "Logistic Regression    0.0000   0.000000  0.0000           0.000000  0.000000   \n",
       "Naive Bayes            0.0000   0.000000  0.0000           0.000000  0.000000   \n",
       "Neural Network         0.6563   0.655297  0.6563           0.638502  0.735512   \n",
       "\n",
       "                           AP  \n",
       "Model                          \n",
       "Decision Tree        0.000000  \n",
       "Random Forest        0.000000  \n",
       "XGB                  0.000000  \n",
       "SVM                  0.000000  \n",
       "KNN                  0.000000  \n",
       "Logistic Regression  0.000000  \n",
       "Naive Bayes          0.000000  \n",
       "Neural Network       0.669619  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('../Resources/Datasets/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model using pickle\n",
    "import pickle\n",
    "filename = '../Models/nn_model.pkl'\n",
    "pickle.dump(nn, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
